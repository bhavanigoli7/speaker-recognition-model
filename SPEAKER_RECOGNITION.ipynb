{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a8fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Audio\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97726649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006b91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e658f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import wave\n",
    "\n",
    "def record_audio(duration, sample_rate, channels, filename):\n",
    "    # Record audio from the microphone\n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=channels)\n",
    "    sd.wait()\n",
    "\n",
    "    # Convert audio data to 16-bit integers\n",
    "    audio_data = (recording * (2 ** 15)).astype('int16')\n",
    "\n",
    "    # Save audio data to WAV file\n",
    "    with wave.open(filename, 'wb') as file:\n",
    "        file.setnchannels(channels)\n",
    "        file.setsampwidth(2)\n",
    "        file.setframerate(sample_rate)\n",
    "        file.writeframes(audio_data.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6cb6e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTER SPEAKER NAMEBhavani1\n",
      "read it:\n",
      "India is a country renowned for its incredible richness in various aspects. One of the key factors contributing to Indias richness is its unparalleled cultural diversity. With a plethora of languages, religions, traditions, and festivals, India is a vibrant tapestry of different cultural threads. From the snowy peaks of the Himalayas to the sun-kissed beaches of Goa, the countrys geographical diversity further enhances its richness.Indias historical significance adds another layer to its richness. It has been a land of ancient civilizations, dynasties, and empires, leaving behind a legacy of awe-inspiring monuments, palaces, temples, and forts. The Taj Mahal, an epitome of architectural brilliance, stands as a symbol of Indias cultural and historical grandeur.Spirituality and philosophy have thrived in India for centuries. The birthplace of religions like Hinduism, Buddhism, Jainism, and Sikhism, India has been a sanctuary for seekers of spiritual enlightenment. Ashrams, pilgrimage sites, and practices like yoga and meditation attract people from all over the world, seeking solace and inner awakening.Art and handicrafts showcase Indias creativity and artistic finesse. From intricate paintings to mesmerizing sculptures, traditional music and dance forms to hand-woven textiles, Indian art forms are a testament to the countrys rich artistic heritage. The skills and craftsmanship of Indian artisans are celebrated globally.Indias biodiversity and natural beauty are extraordinary. Vast stretches of lush forests, majestic mountains, pristine rivers, and diverse wildlife make India a paradise for nature lovers. National parks and wildlife sanctuaries preserve the countrys ecological treasures, reflecting its commitment to conservation.The culinary delights of India are a treat for the taste buds. Indian cuisine, with its myriad flavors, spices, and regional specialties, showcases the countrys gastronomic richness. From aromatic biryanis to spicy curries, from delectable sweets to street food, Indian cuisine is a delightful journey of flavors.Indias traditional practices, such as Ayurveda, yoga, astrology, and traditional farming methods, add to its richness. These ancient knowledge systems have been passed down through generations, contributing to the well-being and sustainability of society.In summary, Indias richness lies in its cultural diversity, historical significance, architectural marvels, spiritual traditions, artistic brilliance, natural beauty, culinary treasures, and traditional practices. This vibrant and multifaceted nation offers a captivating experience for those seeking to explore its richness and immerse themselves in its diverse tapestry of traditions and heritage.\n",
      "DO U WANT TO CONTINUE ? (1/0)0\n"
     ]
    }
   ],
   "source": [
    "x=1\n",
    "while(x):\n",
    "    folder=input('ENTER SPEAKER NAME')\n",
    "    # Example usage\n",
    "    folder_name = \"custome_audio/audio/\"+folder\n",
    "    create_folder(folder_name)\n",
    "    print('read it:\\nIndia is a country renowned for its incredible richness in various aspects. One of the key factors contributing to Indias richness is its unparalleled cultural diversity. With a plethora of languages, religions, traditions, and festivals, India is a vibrant tapestry of different cultural threads. From the snowy peaks of the Himalayas to the sun-kissed beaches of Goa, the countrys geographical diversity further enhances its richness.Indias historical significance adds another layer to its richness. It has been a land of ancient civilizations, dynasties, and empires, leaving behind a legacy of awe-inspiring monuments, palaces, temples, and forts. The Taj Mahal, an epitome of architectural brilliance, stands as a symbol of Indias cultural and historical grandeur.Spirituality and philosophy have thrived in India for centuries. The birthplace of religions like Hinduism, Buddhism, Jainism, and Sikhism, India has been a sanctuary for seekers of spiritual enlightenment. Ashrams, pilgrimage sites, and practices like yoga and meditation attract people from all over the world, seeking solace and inner awakening.Art and handicrafts showcase Indias creativity and artistic finesse. From intricate paintings to mesmerizing sculptures, traditional music and dance forms to hand-woven textiles, Indian art forms are a testament to the countrys rich artistic heritage. The skills and craftsmanship of Indian artisans are celebrated globally.Indias biodiversity and natural beauty are extraordinary. Vast stretches of lush forests, majestic mountains, pristine rivers, and diverse wildlife make India a paradise for nature lovers. National parks and wildlife sanctuaries preserve the countrys ecological treasures, reflecting its commitment to conservation.The culinary delights of India are a treat for the taste buds. Indian cuisine, with its myriad flavors, spices, and regional specialties, showcases the countrys gastronomic richness. From aromatic biryanis to spicy curries, from delectable sweets to street food, Indian cuisine is a delightful journey of flavors.Indias traditional practices, such as Ayurveda, yoga, astrology, and traditional farming methods, add to its richness. These ancient knowledge systems have been passed down through generations, contributing to the well-being and sustainability of society.In summary, Indias richness lies in its cultural diversity, historical significance, architectural marvels, spiritual traditions, artistic brilliance, natural beauty, culinary treasures, and traditional practices. This vibrant and multifaceted nation offers a captivating experience for those seeking to explore its richness and immerse themselves in its diverse tapestry of traditions and heritage.')\n",
    "    for i in range(100):\n",
    "        # Example usage\n",
    "        duration = 2  # Duration of audio recording in seconds\n",
    "        sample_rate = 44100  # Sample rate of audio recording\n",
    "        channels = 2  # Number of audio channels (1 for mono, 2 for stereo)\n",
    "        filename = \"custome_audio/audio/\"+folder+'/'+folder+str(i+1)+'.wav'  # Output file name\n",
    "\n",
    "        # Record audio from the microphone and save it as a WAV file\n",
    "        record_audio(duration, sample_rate, channels, filename)\n",
    "    x=int(input('DO U WANT TO CONTINUE ? (1/0)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8655cd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d21423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc35b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761cdf86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a6a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40ced3ec",
   "metadata": {},
   "source": [
    "Copy dataset to arrange audio and noise in different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730f341b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cp -r \"C:/Users/bhava/surge_classes/SPEECH_PROJECTcustome_audio\" ./"
   ]
  },
  {
   "cell_type": "raw",
   "id": "655d3084",
   "metadata": {},
   "source": [
    "Get the data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a240d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"C:/Users/bhava/surge_classes/SPEECH_PROJECT/custome_audio\"\n",
    "audio_folder = \"audio\"\n",
    "noise_folder = \"noise\"\n",
    "\n",
    "audio_path = os.path.join(data_directory, audio_folder)\n",
    "noise_path = os.path.join(data_directory, noise_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7e0f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/bhava/surge_classes/SPEECH_PROJECT/custome_audio\\\\audio'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_path"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2fef32f8",
   "metadata": {},
   "source": [
    "set all the parameters for training and other purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3f1baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_split = 0.1\n",
    "\n",
    "shuffle_seed = 43\n",
    "\n",
    "sample_rate = 22050\n",
    "\n",
    "scale = 0.5\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62a7920e",
   "metadata": {},
   "source": [
    "arrange audio and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b105417",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(data_directory):\n",
    "    if os.path.isdir(os.path.join(data_directory, folder)):\n",
    "        if folder in [audio_folder, noise_folder]:\n",
    "            \n",
    "            continue\n",
    "        elif folder in [\"other\", \"_background_noise_\"]:\n",
    "            \n",
    "            shutil.move(\n",
    "                os.path.join(data_directory, folder),\n",
    "                os.path.join(noise_path, folder),\n",
    "            )\n",
    "        else:\n",
    "            shutil.move(\n",
    "                os.path.join(data_directory, folder),\n",
    "                os.path.join(audio_path, folder),\n",
    "            )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5c26754",
   "metadata": {},
   "source": [
    "Get the list of all noise files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b9bab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_paths = []\n",
    "for subdir in os.listdir(noise_path):\n",
    "    subdir_path = Path(noise_path) / subdir\n",
    "    if os.path.isdir(subdir_path):\n",
    "        noise_paths += [\n",
    "            os.path.join(subdir_path, filepath)\n",
    "            for filepath in os.listdir(subdir_path)\n",
    "            if filepath.endswith(\".wav\")\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f5a2789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\bhava\\\\surge_classes\\\\SPEECH_PROJECT\\\\custome_audio\\\\noise\\\\other\\\\exercise_bike.wav',\n",
       " 'C:\\\\Users\\\\bhava\\\\surge_classes\\\\SPEECH_PROJECT\\\\custome_audio\\\\noise\\\\other\\\\pink_noise.wav',\n",
       " 'C:\\\\Users\\\\bhava\\\\surge_classes\\\\SPEECH_PROJECT\\\\custome_audio\\\\noise\\\\_background_noise_\\\\10convert.com_Audience-Claps_daSG5fwdA7o.wav',\n",
       " 'C:\\\\Users\\\\bhava\\\\surge_classes\\\\SPEECH_PROJECT\\\\custome_audio\\\\noise\\\\_background_noise_\\\\doing_the_dishes.wav',\n",
       " 'C:\\\\Users\\\\bhava\\\\surge_classes\\\\SPEECH_PROJECT\\\\custome_audio\\\\noise\\\\_background_noise_\\\\dude_miaowing.wav',\n",
       " 'C:\\\\Users\\\\bhava\\\\surge_classes\\\\SPEECH_PROJECT\\\\custome_audio\\\\noise\\\\_background_noise_\\\\running_tap.wav']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_paths"
   ]
  },
  {
   "cell_type": "raw",
   "id": "594d38c9",
   "metadata": {},
   "source": [
    "Split noise into chunks of 16,000 steps each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82d301ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = (\n",
    "    \"for dir in `ls -1 \" + noise_path + \"`; do \"\n",
    "    \"for file in `ls -1 \" + noise_path + \"/$dir/*.wav`; do \"\n",
    "    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n",
    "    \"$file | grep sample_rate | cut -f2 -d=`; \"\n",
    "    \"if [ $sample_rate -ne 16000 ]; then \"\n",
    "    \"ffmpeg -hide_banner -loglevel panic -y \"\n",
    "    \"-i $file -ar 16000 temp.wav; \"\n",
    "    \"mv temp.wav $file; \"\n",
    "    \"fi; done; done\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "015f840a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(22050, shape=(), dtype=int32)\n",
      "tf.Tensor(22050, shape=(), dtype=int32)\n",
      "tf.Tensor(44100, shape=(), dtype=int32)\n",
      "Sampling rate for C:\\Users\\bhava\\surge_classes\\SPEECH_PROJECT\\custome_audio\\noise\\_background_noise_\\10convert.com_Audience-Claps_daSG5fwdA7o.wav is incorrect\n",
      "tf.Tensor(22050, shape=(), dtype=int32)\n",
      "tf.Tensor(22050, shape=(), dtype=int32)\n",
      "tf.Tensor(22050, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "os.system(command)\n",
    "def load_noise_sample(path):\n",
    "    sample, sampling_rate = tf.audio.decode_wav(\n",
    "        tf.io.read_file(path), desired_channels=1\n",
    "    )\n",
    "    print(sampling_rate)\n",
    "    if sampling_rate == sample_rate:\n",
    "        slices = int(sample.shape[0] / sample_rate)\n",
    "        sample = tf.split(sample[: slices * sample_rate], slices)\n",
    "        return sample\n",
    "    else:\n",
    "        print(\"Sampling rate for\",path, \"is incorrect\")\n",
    "        return None\n",
    "\n",
    "\n",
    "noises = []\n",
    "for path in noise_paths:\n",
    "    sample = load_noise_sample(path)\n",
    "    if sample:\n",
    "        noises.extend(sample)\n",
    "noises = tf.stack(noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6be4585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  ...\n",
      "  [ 0.00152588]\n",
      "  [ 0.0274353 ]\n",
      "  [ 0.03463745]]\n",
      "\n",
      " [[ 0.02236938]\n",
      "  [ 0.01980591]\n",
      "  [ 0.03091431]\n",
      "  ...\n",
      "  [ 0.02532959]\n",
      "  [-0.00656128]\n",
      "  [ 0.00299072]]\n",
      "\n",
      " [[ 0.02719116]\n",
      "  [ 0.01367188]\n",
      "  [-0.01776123]\n",
      "  ...\n",
      "  [ 0.00491333]\n",
      "  [ 0.02386475]\n",
      "  [ 0.01412964]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.17727661]\n",
      "  [-0.0687561 ]\n",
      "  [ 0.03491211]\n",
      "  ...\n",
      "  [-0.06976318]\n",
      "  [-0.09143066]\n",
      "  [-0.0296936 ]]\n",
      "\n",
      " [[ 0.04153442]\n",
      "  [ 0.02423096]\n",
      "  [-0.00283813]\n",
      "  ...\n",
      "  [-0.09466553]\n",
      "  [ 0.04885864]\n",
      "  [ 0.06637573]]\n",
      "\n",
      " [[-0.06341553]\n",
      "  [-0.02102661]\n",
      "  [ 0.08428955]\n",
      "  ...\n",
      "  [-0.09603882]\n",
      "  [ 0.03704834]\n",
      "  [ 0.12103271]]], shape=(338, 22050, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(noises)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e137d313",
   "metadata": {},
   "source": [
    "DATASET GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97ac1c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_and_labels_to_dataset(audio_paths, labels):\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
    "    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    return tf.data.Dataset.zip((audio_ds, label_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "483440e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_audio(path):\n",
    "    audio = tf.io.read_file(path)\n",
    "    audio, _ = tf.audio.decode_wav(audio, 1, sample_rate)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "raw",
   "id": "723de04b",
   "metadata": {},
   "source": [
    "add noise to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36e1f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(audio, noises=None, scale=0.5):\n",
    "    if noises is not None:\n",
    "        tf_rnd = tf.random.uniform(\n",
    "            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n",
    "        )\n",
    "        noise = tf.gather(noises, tf_rnd, axis=0)\n",
    "\n",
    "        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n",
    "        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n",
    "\n",
    "        audio = audio + noise * prop * scale\n",
    "\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a41dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_fft(audio):\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    fft = tf.signal.fft(\n",
    "        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n",
    "    )\n",
    "    fft = tf.expand_dims(fft, axis=-1)\n",
    "\n",
    "    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d60ab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alekhya', 'bhavani', 'joharika', 'keerthi', 'likitha', 'parvathi', 'sunanda']\n",
      "Speaker: alekhya\n",
      "Speaker: bhavani\n",
      "Speaker: joharika\n",
      "Speaker: keerthi\n",
      "Speaker: likitha\n",
      "Speaker: parvathi\n",
      "Speaker: sunanda\n"
     ]
    }
   ],
   "source": [
    "class_names = os.listdir(audio_path)\n",
    "print(class_names,)\n",
    "\n",
    "audio_paths = []\n",
    "labels = []\n",
    "for label, name in enumerate(class_names):\n",
    "    print(\"Speaker:\",(name))\n",
    "    dir_path = Path(audio_path) / name\n",
    "    speaker_sample_paths = [\n",
    "        os.path.join(dir_path, filepath)\n",
    "        for filepath in os.listdir(dir_path)\n",
    "        if filepath.endswith(\".wav\")\n",
    "    ]\n",
    "    audio_paths += speaker_sample_paths\n",
    "    labels += [label] * len(speaker_sample_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3de3a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle to generate random data\n",
    "rng = np.random.RandomState(shuffle_seed)\n",
    "rng.shuffle(audio_paths)\n",
    "rng = np.random.RandomState(shuffle_seed)\n",
    "rng.shuffle(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "381a8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation\n",
    "num_val_samples = int(valid_split * len(audio_paths))\n",
    "train_audio_paths = audio_paths[:-num_val_samples]\n",
    "train_labels = labels[:-num_val_samples]\n",
    "\n",
    "\n",
    "valid_audio_paths = audio_paths[-num_val_samples:]\n",
    "valid_labels = labels[-num_val_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d58ed048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets, one for training and the other for validation\n",
    "train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n",
    "train_ds = train_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
    "    batch_size\n",
    ")\n",
    "\n",
    "valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
    "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=shuffle_seed).batch(32)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b03cd71",
   "metadata": {},
   "source": [
    "feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d119f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to the training set\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (add_noise(x, noises, scale=scale), y),\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    ")\n",
    "\n",
    "# Transform audio wave to the frequency domain using `audio_to_fft`\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "\n",
    "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_ds = valid_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "valid_ds = valid_ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c32c0d15",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66845387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f51bbd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 11025, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 11025, 128)   512         ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 11025, 128)   0           ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 11025, 128)   49280       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 11025, 128)   0           ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 11025, 128)   49280       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 11025, 128)   256         ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 11025, 128)   0           ['conv1d_17[0][0]',              \n",
      "                                                                  'conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 11025, 128)   0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 5512, 128)   0           ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling1d (AveragePool  (None, 1837, 128)   0           ['max_pooling1d_4[0][0]']        \n",
      " ing1D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 235136)       0           ['average_pooling1d[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          60195072    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          32896       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 7)            903         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 60,328,199\n",
      "Trainable params: 60,328,199\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, conv_num = 3, activation = \"relu\"):\n",
    "    s = keras.layers.Conv1D(filters, 1, padding = \"same\")(x)\n",
    "    \n",
    "    for i in range(conv_num - 1):\n",
    "        x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n",
    "        x = keras.layers.Activation(activation)(x)\n",
    "    \n",
    "    x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n",
    "    x = keras.layers.Add()([x, s])\n",
    "    x = keras.layers.Activation(activation)(x)\n",
    "    \n",
    "    return keras.layers.MaxPool1D(pool_size = 2, strides = 2)(x)\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = keras.layers.Input(shape = input_shape, name = \"input\")\n",
    "    \n",
    "    x = residual_block(inputs, 16, 2)\n",
    "    x = residual_block(inputs, 32, 2)\n",
    "    x = residual_block(inputs, 64, 3)\n",
    "    x = residual_block(inputs, 128, 3)\n",
    "    x = residual_block(inputs, 128, 3)\n",
    "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    \n",
    "    outputs = keras.layers.Dense(num_classes, activation = \"softmax\", name = \"output\")(x)\n",
    "    \n",
    "    return keras.models.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "model = build_model((sample_rate // 2, 1), len(class_names))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \n",
    "\n",
    "model_save_filename = \"model.h5\"\n",
    "\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(model_save_filename, monitor=\"val_accuracy\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b190ca8",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca8c6919",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/26 [==============================] - 69s 3s/step - loss: 22.5500 - accuracy: 0.2365 - val_loss: 3.1786 - val_accuracy: 0.1857\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 80s 3s/step - loss: 1.3570 - accuracy: 0.4873 - val_loss: 1.6463 - val_accuracy: 0.5429\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 71s 3s/step - loss: 0.6352 - accuracy: 0.7698 - val_loss: 0.7161 - val_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 74s 3s/step - loss: 0.4290 - accuracy: 0.8508 - val_loss: 0.6802 - val_accuracy: 0.8143\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 77s 3s/step - loss: 0.4243 - accuracy: 0.8556 - val_loss: 0.5999 - val_accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 73s 3s/step - loss: 0.2490 - accuracy: 0.9079 - val_loss: 0.4567 - val_accuracy: 0.8714\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 68s 3s/step - loss: 0.2290 - accuracy: 0.9079 - val_loss: 0.5118 - val_accuracy: 0.8429\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 68s 3s/step - loss: 0.2183 - accuracy: 0.9175 - val_loss: 0.5807 - val_accuracy: 0.8429\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 70s 3s/step - loss: 0.8582 - accuracy: 0.7540 - val_loss: 0.6279 - val_accuracy: 0.7714\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 69s 3s/step - loss: 0.3557 - accuracy: 0.8873 - val_loss: 0.6807 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_ds,\n",
    "    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c49c8176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 506ms/step - loss: 0.6807 - accuracy: 0.8000\n",
      "Accuracy of model: [0.6807418465614319, 0.800000011920929]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of model:\",model.evaluate(valid_ds))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f83e92a0",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da54097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Speaker:\u001b[92m sunanda\u001b[0m\tPredicted:\u001b[92m sunanda\u001b[0m\n",
      "Welcome\n",
      "The speaker is sunanda\n",
      "Speaker:\u001b[92m bhavani\u001b[0m\tPredicted:\u001b[92m bhavani\u001b[0m\n",
      "Welcome\n",
      "The speaker is bhavani\n",
      "Speaker:\u001b[92m likitha\u001b[0m\tPredicted:\u001b[92m likitha\u001b[0m\n",
      "Welcome\n",
      "The speaker is likitha\n",
      "Speaker:\u001b[92m bhavani\u001b[0m\tPredicted:\u001b[92m bhavani\u001b[0m\n",
      "Welcome\n",
      "The speaker is bhavani\n",
      "Speaker:\u001b[92m bhavani\u001b[0m\tPredicted:\u001b[92m bhavani\u001b[0m\n",
      "Welcome\n",
      "The speaker is bhavani\n"
     ]
    }
   ],
   "source": [
    "SAMPLES_TO_DISPLAY =5\n",
    "\n",
    "test_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
    "test_ds = test_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
    "    batch_size\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(lambda x, y: (add_noise(x, noises, scale=scale), y))\n",
    "\n",
    "for audios, labels in test_ds.take(1):\n",
    "    ffts = audio_to_fft(audios)\n",
    "    y_pred = model.predict(ffts)\n",
    "    rnd = np.random.randint(0, batch_size, SAMPLES_TO_DISPLAY)\n",
    "    #print(rnd)\n",
    "    audios = audios.numpy()[rnd, :, :]\n",
    "    labels = labels.numpy()[rnd]\n",
    "    y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
    "\n",
    "    for index in range(SAMPLES_TO_DISPLAY):\n",
    "        print(\n",
    "            \"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n",
    "                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n",
    "                class_names[labels[index]],\n",
    "                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n",
    "                class_names[y_pred[index]],\n",
    "            )\n",
    "        )\n",
    "        if labels[index] ==y_pred[index]:\n",
    "            print(\"Welcome\")\n",
    "        else:\n",
    "            print(\"Sorry\")\n",
    "        print(\"The speaker is\" if labels[index] == y_pred[index] else \"\", class_names[y_pred[index]])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe0fbb82",
   "metadata": {},
   "source": [
    "Predcit the speaker from the test dataset for real time pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a69c8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_to_dataset(audio_paths):\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
    "    return tf.data.Dataset.zip((path_ds))\n",
    "\n",
    "def predict(path, labels):\n",
    "    test = paths_and_labels_to_dataset(path, labels)\n",
    "\n",
    "\n",
    "    test = test.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
    "    batch_size\n",
    "    )\n",
    "    test = test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "    test = test.map(lambda x, y: (add_noise(x, noises, scale=scale), y))\n",
    "\n",
    "    for audios, labels in test.take(1):\n",
    "        ffts = audio_to_fft(audios)\n",
    "        y_pred = model.predict(ffts)\n",
    "        rnd = np.random.randint(0, 1, 1)\n",
    "        audios = audios.numpy()[rnd, :]\n",
    "        labels = labels.numpy()[rnd]\n",
    "        y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
    "\n",
    "    for index in range(1):\n",
    "            print(\n",
    "            \"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n",
    "            \"[92m\",y_pred[index],\n",
    "                \"[92m\", y_pred[index]\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            print(\"Speaker Predicted:\",class_names[y_pred[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b5993e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba5c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb958b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30,35):\n",
    "    #duration = 2  # Duration of audio recording in seconds\n",
    "    #sample_rate = 44100  # Sample rate of audio recording\n",
    "    #channels = 2\n",
    "    #filename = 'test/input'+str(i+1)+'.wav'  # Output file name\n",
    "    record_audio(duration=2,sample_rate=44100, channels=2, filename='test/input'+str(i+1)+'.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9a5feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56f1ab83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 183ms/step\n",
      "Speaker:\u001b[92m 2\u001b[0m\tPredicted:\u001b[92m 2\u001b[0m\n",
      "Speaker Predicted: joharika\n"
     ]
    }
   ],
   "source": [
    "path = [\"C:/Users/bhava/surge_classes/SPEECH_PROJECT/test/input1.wav\"]\n",
    "try:\n",
    "    predict(path, labels)\n",
    "except:\n",
    "    print(\"Error! Check if the file correctly passed or not!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a278b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd211767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
